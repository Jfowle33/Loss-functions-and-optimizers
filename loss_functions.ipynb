{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6982c28",
   "metadata": {},
   "source": [
    "A look at different loss functions and how to code them in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b8dad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5951a2a9",
   "metadata": {},
   "source": [
    "$$RMSE_{f0} = [\\sum_{i=1}^N (z_{fi} - z_{0i}/N]^2$$\n",
    "\n",
    "notation (Barnston, 1992): We are taking the difference between predicted values and actual values, average them, and square.\n",
    "\n",
    "$\\sum$ = summation (“add up”)\n",
    "\n",
    "$(z_{fi} – z_{oi})^2$ = differences, squared\n",
    "\n",
    "N = sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4457625",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.array([0.000, 0.166, 0.333])\n",
    "y_true = np.array([0.000, 0.254, 0.998])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "823878c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    differences = predictions - targets\n",
    "    differences_squared = differences ** 2\n",
    "    mean_of_differences_squared = differences_squared.mean()\n",
    "    rmse_val = np.sqrt(mean_of_differences_squared)\n",
    "    return rmse_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff54bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_val = rmse(y_hat, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9301e57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error is:0.3872849941150143\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean squared error is:\" + str(rmse_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67abfa8f",
   "metadata": {},
   "source": [
    "In the next loss function we will be looking at mean absolute error\n",
    "\n",
    "$${\\displaystyle \\mathrm {MAE} ={\\frac {\\sum _{i=1}^{n}\\left|y_{i}-x_{i}\\right|}{n}}={\\frac {\\sum _{i=1}^{n}\\left|e_{i}\\right|}{n}}.}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0917773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(predictions, targets):\n",
    "    differences = predictions - targets\n",
    "    absolute_differences = np.absolute(differences)\n",
    "    mean_absolute_differences = absolute_differences.mean()\n",
    "    return mean_absolute_differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "681e8dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_val = mae(y_hat, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ed59d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error is:0.251\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean absolute error is:\" + str(mae_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6a99646",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array([[0.25,0.25,0.25,0.25], [0.01,0.01,0.01,0.96]])\n",
    "targets = np.array([[0,0,0,1], [0,0,0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b02fb3",
   "metadata": {},
   "source": [
    "The cross-entropy of the distribution ${\\displaystyle q}$ relative to a distribution ${\\displaystyle p}$ over a given set is defined as follows:\n",
    "\n",
    "$${\\displaystyle H(p,q)=-\\operatorname {E} _{p}[\\log q]}$$,\n",
    "\n",
    "where ${\\displaystyle E_{p}[\\cdot ]}$ is the expected value operator with respect to the distribution ${\\displaystyle p}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f46a76eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(predictions, targets, epsilon=1e-10):\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    ce_loss = -np.sum(np.sum(targets * np.log(predictions + 1e-5)))/N\n",
    "    return ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60dd7290",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy_loss = cross_entropy(predictions, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37208677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross entropy loss is:0.7135329699138555\n"
     ]
    }
   ],
   "source": [
    "print(\"Cross entropy loss is:\" + str(cross_entropy_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
